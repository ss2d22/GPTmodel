{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c936ba66-9ff2-487d-8c00-cdb6d7207582",
   "metadata": {},
   "source": [
    "# Making a Simple Bigram model with Romeo and Juliet Book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d95fde-e3cf-4088-840b-9487310ce515",
   "metadata": {},
   "source": [
    "## 1) read the text file with data and store it in a variable\n",
    "    the contents of the book was stored in a `data.txt file` and all it['s content is read and copied to a variable named text.\n",
    "    the length and the first 300 characters was printed to test if it was working and once confirmed moved on the second part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29f2d4b2-192e-4ce0-8c80-71ae53f9da15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142466\n",
      "﻿THE TRAGEDY OF ROMEO AND JULIET\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents\n",
      "\n",
      "THE PROLOGUE.\n",
      "\n",
      "ACT I\n",
      "Scene I. A public place.\n",
      "Scene II. A Street.\n",
      "Scene III. Room in Capulet’s House.\n",
      "Scene IV. A Street.\n",
      "Scene V. A Hall in Capulet’s House.\n",
      "\n",
      "ACT II\n",
      "CHORUS.\n",
      "Scene I. An open place adjoining Capulet’s Garden.\n",
      "Scen\n"
     ]
    }
   ],
   "source": [
    "with open('data.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()  \n",
    "print(len(text))\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48074416-f5f4-4c5e-b090-5ddd0c0316bf",
   "metadata": {},
   "source": [
    "## 2) make a sorted set of all the characters in the dataset\n",
    "\n",
    "    a set of all the unique characters in the data was taken using the `set()` method and the result was passed into the `sorted()` method and copied   to the `chars` variable, The result is printed for testing and visualisation purposes. This helps us have a vocabulary of sorts to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a664f27-da77-4582-8a2d-ef9096131346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '&', ',', '-', '.', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'æ', '—', '‘', '’', '“', '”', '\\ufeff']\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a86e1-2305-40ea-a9ac-8c0155d15abc",
   "metadata": {},
   "source": [
    " ### why do the above ? \n",
    "\n",
    "  this lets us work with tokenizers which comes with encoders and decoders, encoders can help us convert all the 71 characters to numbers. we will be making a character level tokenizer below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbca93b-33c7-4c03-9789-ad1d876ae256",
   "metadata": {},
   "source": [
    "## 3) make a basic character-level tokenizer\n",
    "\n",
    "\n",
    "In order to make the character level tokenizer two dictionaries are first made. **'string_to_integer = { ch:i for i,ch in enumerate(chars) }'** enumerate over each character in the array and assign it an unique number making the first dictionary and reverse for integer to string making the second dictionary .\n",
    "\n",
    "**e.g. :** if  'chars = ['a', 'b', 'c']' then these will be the values of the two dictionaries :\n",
    "string_to_integer = {'a': 0, 'b': 1, 'c': 2}\n",
    "integer_to_string = {0: 'a', 1: 'b', 2: 'c'}\n",
    "\n",
    "encoder takes a string s and converts it to a list of integers. For each character c in the string s, it looks up its integer value using the string_to_integer dictionary. The result is a list of integers corresponding to each character.\n",
    "\n",
    "decoder takes a list of integers l and converts it back to a string. For each integer i in the list l, it looks up the corresponding character using the integer_to_string dictionary. It then joins these characters into a single string.\n",
    "\n",
    "**another e.g:** \n",
    "\n",
    "encoder('abc')  # e.g. Output: [0, 1, 2]\n",
    "\n",
    "decoder([0, 1, 2])  # e.g. Output: 'abc'\n",
    "\n",
    "these two methods combied helps have the functionality of a basic character-level tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b926ad32-05f5-4e91-8abe-4a17530f5c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62, 58, 51, 44, 57, 46, 51, 44]\n",
      "yungting\n"
     ]
    }
   ],
   "source": [
    "string_to_integer = { ch:i for i,ch in enumerate(chars) }\n",
    "integer_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encoder = lambda s: [string_to_integer[c] for c in s]\n",
    "decoder = lambda l: ''.join([integer_to_string[i] for i in l])\n",
    "\n",
    "encoded_yungting = encoder('yungting')\n",
    "print(encoded_yungting)\n",
    "decoded_yungting = decoder(encoded_yungting)\n",
    "print(decoded_yungting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24a9884-377a-4aa5-88f0-6de60585f8f5",
   "metadata": {},
   "source": [
    "### More info on tokenizers \n",
    "\n",
    " #### Types of tokenizers \n",
    "\n",
    " #### 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yungting-gpt",
   "language": "python",
   "name": "yugpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
